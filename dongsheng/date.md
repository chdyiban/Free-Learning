日期|工作学习情况
:-:|:-
8.1|今天复习了一下tornado框架和sqlachemy模块，学习使用alembic模块进行数据库迁移
8.2|今天进度可以算无，看了看python里面的上下文管理器，else块，以及刚刚开始看如何将使用协程
8.3|接着看协程，从生成器到协程的转变
8.4|1、今天学习了终止协程和异常处理，以及在协程中返回值</br>2、初步理解了一点yield from这个语言结构使用方法和原理，虽然知道它很强大，但是还是不能理解这么复杂的语法的意义
8.5|今天学习了一个用来处理并发的模块concurrent.futures，主要的两个类ThreadPoolExecutor和ProcessPoolExecutor内部维护着一个线程池或者进程池，感觉很方便，但是实际使用的时候可能封装级别较低的Threading和multiprocessing这两个模块可能更加灵活。
8.6|今日进度：无
8.7|1、今天学习了协程的使用，两个扩展包greenlet和gevent模块，使用协程实现并发</br>2、看了一下python标准库里面的协程asyncio模块，不过感觉很难，暂时还没有看懂。
8.8|今日进度：无
8.9|1、今天继续学习了asyncio模块</br>2、今天对之前线程池，进程池以及线程进程通信做了一个小结
8.10|无
8.11|1、学习了tornado框架中的websocket的使用</br>2、开始学习python的元编程，正在看动态属性和特性
8.12|1、继续学习元编程，创建描述符</br>2、正在学习shell编程
8.13|1、学习创建元类，以及与普通类的关系</br>2、复习了tornado异步的使用
8.14|1、学习shell编程，if，for，while语句，按照视频写了个简单的MySQL数据库自动备份脚本</br>2、学习了jQuery中使用Ajax与tornado进行数据交互
8.15|无
8.16|学习shell编程，学习了until，case，select语句以及数组和函数，学习sed，grep，awk以及find的基本使用
8.17|学习使用Supervisor来监控tornado进程
8.18|1、学习numpy的基本使用</br>2、学习使用pandas进行数据处理
8.19|1、学习pandas里面一些处理数据的操作</br>2、今天开始学习matplotlib
8.20|今日进度：继续学习了一点点matplotlib进行数据可视化
8.21~9.1|进度几乎为无
9.2|今日进度：学习一个对matplotlib进一步封装的模块seaborn
9.3|今日进度：1、测试了一下图书馆，在学校也没办法访问，明天再用校园网试一下</br>2、跟着视频学习了一些线性回归方面的知识
9.4~9.12|今日进度：几乎为无，没怎么记录
9.13|1、今天尝试写了异步代码替换之前使用requests库写的阻塞代码，之前的代码完全没有用到tornado的异步特性，对于性能没有什么提升。</br>2、重新看了看tornado里面关于协程的使用以及python中新加入的关键词async和await
9.15|完成部署，在服务器创建了一个拥有sudo权限的用户py，编译安装了python3.7和一些附件，以及使用python2安装了supervisor监控tornado进程，修改了nginx配置文件，增加了upstream和server用来做tornado的负载均衡。使用python2安装了virtualenv来创建虚拟环境
9.16|无
9.17|1、学习了一些关于代码检查代码测试的内容</br>2、看看了逻辑回归算法的讲解视频
9.18|今日进度：无
9.19|今日进度：折腾了一天的win0子系统上面的Linux，感觉win10的子系统有点坑，入门学Linux还是挺方便的，另外学了一些网络测试命令
9.20|学习基本的设计模式，使用python实现单例模式和mixin模式，在python中应该可以很方便的创建一个可扩展的动态生成不同实例的代码，不过暂时遇到一个小bug，等待解决
9.21|今日进度：跟着视频做了一个梯度下降求解线性回归的案例
9.22|今日进度：看了一遍一个简易版的scrapy的中文翻译，使用爬虫框架感觉简直是一应俱全，很强大很方便。今天主要学习里面的操作流程和css选择器、xpath以及它的全局命令
9.23|1、看scrapy的官方文档，学习了几种不同的爬虫的使用、将爬取的数据写入数据库以及一个非常好用的链接提取器。</br>2、初步分析了一下先锋家园这个网站，感觉很适合练手，比较整齐，可能个别页面需要更改爬取的规则，准备直接用框架将所有板块的链接提取出来，就可以直接爬新闻的链接了，在框架里面感觉想要什么就有什么，提取链接，分页，以及文本内容抓取这些都很方便。
9.24|学习scrapy的文档，今天爬取先锋家园所有版块的链接，然后准备进行进一步的数据抓取，但是似乎在这个地方遇到了一个问题，框架在提取链接的时候自动进行了深度遍历，然后当我希望进行再次爬取的时候会失败，但是当我在请求中设置参数使得可以重复爬取的时候，这个时候又会陷入爬行循环，会重复好几次我所做的工作，或许这是其他失误操作所导致。。。。。。在写今日进度的时候问题刚好解决，但是有些问题还是应该继续深入框架
9.25|今日进度：先锋家园爬虫爬取解析部分代码基本完成，正在增加一个redis的过滤操作和将数据写入MySQL数据库
9.26|写完了先锋家园的爬虫，但是由于最后我的ip被限制了（本来还可以用的，可能测试的次数太多了，被制裁了），估计235和236两个服务器也是由于访问次数过多所以造成的无法访问学校网站。明天写个代理应该就可以了
9.27|无
9.28|先锋家园爬虫已经完成，现在先用我的数据库进行测试，可以了的话就可以直接爬到235的数据库里面了
9.29|在236上面装了个redis服务，调试了一下配置文件以及redis和mysql的连接情况，解决在后台运行爬虫的问题，解决了一个配置日志输出文件的小问题，爬虫正常运行
9.30~10.7|国庆七天没有做什么，深入看了一遍scrapy的文档，各种中间件以及配置（不过感觉看完就忘得差不多了。。），另外在GitHub上面找到了一个爬取代理的项目，还是很不错，用tornado以及scrapy结合写的一个项目，部署到了我的服务器上面，感觉深入理解理解里面tornado和scrapy结合的地方很有好处
10.8|今天将爬虫数据库去重以及字段修改完了，改进了一下代码，还没有进行最终测试
10.9|先锋家园爬虫测试完毕，优化了部分代码，正在将其加入到定时任务中
10.10|无
10.11|1、先锋家园爬虫完毕，但是更改了tag和做了数据库过滤之后感觉效率低了很多。</br>2、信息门户爬虫刚开始，使用scrapy的CookiesMiddleware中间件使用cookie</br>找到了一本不错的书《learning+scrapy》，大概可以找到嵌入web以及合理使用性能的方法
10.12~10.13|1、先锋家园爬虫完毕</br>2、信息门户爬虫完毕</br>3、对于爬虫框架的使用还不够熟练以及对于异步框架twisted使用还不会，代码还需要优化，另外由于可能由于数据库的原因造成效率低，这个地方也需要优化
10.14|1、改了改之前爬虫的bug，一个由于title没有做转义导致的错误和一个由于author太长导致的错误以及在信息门户的新闻有部分会跳转到其他链接，这个直接在框架里面设置为禁止访问了。另外有一个bug，似乎每次爬虫爬取文章数量总是预计的两倍，这个有待解决。</br>2、继续看scrapy的文档和《learning scrapy》，学习使用Item Loader来处理响应，有助于简化代码
